{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from layer .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_cap_thickness 17.65592033642668\n",
      "layer_thicknesses [501.00581087953816, 356.5945398451761]\n",
      "max_cube_length 1765.592033642668\n",
      "total_particles 32\n",
      "total_volume 267787432.79646492\n"
     ]
    }
   ],
   "source": [
    "# input text file in order of layers bottom to top\n",
    "text_files = [\"36a_COMSOL_input.txt\", \"36b_COMSOL_input.txt\"]\n",
    "\n",
    "test = text_files[0]\n",
    "\n",
    "# keep track of thickness of each layer, max cube length, number of particles of each layer\n",
    "layer_thicknesses = []\n",
    "max_cube_length = 0\n",
    "particle_numbers = []\n",
    "total_particles = 0\n",
    "total_volume = 0\n",
    "\n",
    "# loop through layer .txt files\n",
    "for file in text_files:\n",
    "    with open(file) as open_file:\n",
    "        data = open_file.read()\n",
    "        split_data = data.split(\"\\n\")\n",
    "\n",
    "        # extract layer thickness\n",
    "        label, str_layer_thickness, unit = split_data[-1].split()\n",
    "        layer_thickness = float(str_layer_thickness)\n",
    "\n",
    "        layer_thicknesses += [layer_thickness]\n",
    "\n",
    "        # extract cube length\n",
    "        label, str_cube_length, unit = split_data[-2].split()\n",
    "        cube_length = float(str_cube_length)\n",
    "\n",
    "        if cube_length > max_cube_length:\n",
    "            max_cube_length = cube_length\n",
    "            \n",
    "        # extract volume\n",
    "        label, str_volume, unit = split_data[-3].split()\n",
    "        total_volume += float(str_volume)\n",
    "            \n",
    "        # extract number of particles\n",
    "        label, str_particle_number = split_data[-4].split()\n",
    "        particle_number = int(str_particle_number)\n",
    "\n",
    "        particle_numbers += [particle_number]\n",
    "        total_particles += particle_number\n",
    "        \n",
    "        # close file\n",
    "        open_file.close()\n",
    "        \n",
    "max_cap_thickness = max_cube_length / 100\n",
    "            \n",
    "print(\"max_cap_thickness\", max_cap_thickness)\n",
    "print(\"layer_thicknesses\", layer_thicknesses)\n",
    "print(\"max_cube_length\", max_cube_length)\n",
    "print(\"total_particles\", total_particles)\n",
    "print(\"total_volume\", total_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update particle numbers to IDs, z-coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_base = 0\n",
    "file_counter = 0\n",
    "height_adjustment = 0\n",
    "with open(\"COMSOL_input.txt\", \"w\") as output_file:\n",
    "#     with open(file) as open_file:\n",
    "#         output_file.writelines(line for line in open_file)\n",
    "    \n",
    "    # loop through layer .txt files\n",
    "    for file in text_files:\n",
    "        with open(file) as open_file:\n",
    "            data = open_file.read()\n",
    "            split_data = data.split(\"\\n\")\n",
    "            \n",
    "            # get rid of data after ***************** delimiter\n",
    "            split_data = split_data[:-5]\n",
    "            \n",
    "            for line in split_data:\n",
    "                label, ID, value, unit = line.split()\n",
    "                ID = int(ID)\n",
    "                value = float(value)\n",
    "                            \n",
    "                if label == \"z\":\n",
    "                    output_file.writelines(label + str(ID + ID_base) + \" \" + str(value + max_cap_thickness + height_adjustment + 1) + unit + \"\\n\")\n",
    "                else:\n",
    "                    output_file.writelines(label + str(ID + ID_base) + \" \" + str(value) + unit + \"\\n\")\n",
    "                    \n",
    "            ID_base += particle_numbers[file_counter]\n",
    "            height_adjustment += (1 + layer_thicknesses[file_counter])\n",
    "            file_counter += 1\n",
    "            \n",
    "            # close layer file\n",
    "            open_file.close()\n",
    "            \n",
    "    output_file.writelines(\"*****************\\n\")\n",
    "    output_file.writelines(\"total_particles \" + str(total_particles) + \"\\n\")        # number of particles\n",
    "    output_file.writelines(\"total_volume \" + str(total_volume) + \"[nm^3]\" + \"\\n\")   # total volume\n",
    "    output_file.writelines(\"cube_length \" + str(max_cube_length) + \"[nm]\" + \"\\n\")   # cube side length\n",
    "    output_file.writelines(\"volume_fraction \" + str(total_volume/cube_length**3) + \"\\n\")       # cube side length\n",
    "    \n",
    "    # close output file\n",
    "    output_file.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
